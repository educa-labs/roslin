{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sk learn classes\n",
    "\n",
    "Clases para generar un pipeline de sk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import json\n",
    "from functools import reduce\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "transformer object that turns the data json into arrays of tokenized words.\n",
    "'''\n",
    "\n",
    "class JsonTransform():\n",
    "    \n",
    "    '''\n",
    "    add category determines if tag category is added to the final arrays.\n",
    "    '''\n",
    "    def __init__(self,add_category=False):\n",
    "        self.add_category = add_category\n",
    "        \n",
    "    '''\n",
    "    returns arrays of word arrays from tags\n",
    "    '''    \n",
    "\n",
    "    \n",
    "    def fit(self,X=None,y=None):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def transform(self,X):\n",
    "        return [ self.tag_array_to_word_array(instance) for instance in self.data_to_tags(data)]\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    returns tag as array of words (no ':').\n",
    "    add_category determines if the tag category is added to the array.\n",
    "    '''\n",
    "    def tag_to_words(self,tag):\n",
    "        category, text = tag.split(\":\")\n",
    "        if self.add_category:\n",
    "            return word_tokenize(\"{} {}\".format(category,text).lower())\n",
    "        return word_tokenize(text.lower())\n",
    "\n",
    "    '''\n",
    "    transforms array of tags into array of words.\n",
    "    add_category determines if the tag categories are added to the text.\n",
    "    '''\n",
    "    def tag_array_to_word_array(self,tags):\n",
    "        aux_tags = list(tags)\n",
    "        aux_tags[0] = self.tag_to_words(tags[0])\n",
    "        return reduce(lambda x,y : x + self.tag_to_words(y),aux_tags)\n",
    "\n",
    "    '''\n",
    "    returns array of tag arrays from original json.\n",
    "    '''\n",
    "    def data_to_tags(self,data):\n",
    "        return [instance[\"tags\"] for instance in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "#constants\n",
    "DATA_PATH=\"data.json\"\n",
    "data = json.load(open(DATA_PATH))\n",
    "json_transformer = JsonTransform(False)\n",
    "documents = json_transformer.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "\n",
    "import numpy as np\n",
    "from gensim import corpora\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculates embedding, mapping a tokenized document to a vector.\n",
    "To calculate the vector we use a weighted average of precomputed Glove Vectors. \n",
    "Weights of the average are given by TFIDF scores.\n",
    "'''\n",
    "\n",
    "class TfIdfGloveTransformer():\n",
    "    \n",
    "    '''\n",
    "    word_embedder is pretrained gensim.KeyedVectors model\n",
    "    \n",
    "    dim is the dimension on word_embedder\n",
    "    '''\n",
    "    def __init__(self,word_embedder,dim=300):\n",
    "        self.word_embedder = word_embedder\n",
    "        self.dim=dim\n",
    "        self.word_dict = corpora.Dictionary(documents,prune_at=None)\n",
    "        self.bows = None\n",
    "        self.tfidf = None\n",
    "        self.token2id = None\n",
    "        \n",
    "    '''\n",
    "    Fits from corpus of tokenized documents.\n",
    "    '''\n",
    "    def fit(self,X,y=None):\n",
    "        self.bows = [self.word_dict.doc2bow(doc) for doc in X]\n",
    "        self.tfidf = TfidfModel(self.bows,normalize=True)\n",
    "        self.token2id = self.word_dict.token2id\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    returns embedding representation of documents in X\n",
    "    '''\n",
    "    \n",
    "    def transform(self,X):\n",
    "        new_bows = [self.word_dict.doc2bow(doc) for doc in X]\n",
    "        result = np.zeros((len(X),self.dim))\n",
    "        # perhaps this can be implemented better in a vectorial way\n",
    "        for i, (doc,bow) in enumerate(zip(X,new_bows)):\n",
    "            score_hash = { tup[0]:tup[1] for tup in self.tfidf.__getitem__(bow,-1)} # threshold\n",
    "            weighted_embeddings = np.array([np.dot(model[word],score_hash[self.token2id[word]]) if word in model else np.zeros((1,self.dim)) for word in doc])\n",
    "            result[i] = np.sum(weighted_embeddings, axis=0)\n",
    "        return result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "# constants\n",
    "GLOVE_PATH= \"glove-sbwc.i25.vec\"\n",
    "vectors = 855380\n",
    "model=KeyedVectors.load_word2vec_format(GLOVE_PATH,limit=vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 300)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.20531225e-01, -1.32767827e-01, -2.40587811e-01, -4.50649503e-01,\n",
       "        5.71917176e-01,  7.97919041e-01,  2.06611624e-01, -2.39433183e-01,\n",
       "       -3.97522111e-01,  6.60949659e-01, -4.01172718e-02, -3.52866864e-01,\n",
       "       -3.64130336e-01, -1.29405238e-01, -6.71148494e-01,  3.34426119e-01,\n",
       "       -3.54335664e-01, -4.58082952e-02,  4.45215941e-01,  2.09159656e-01,\n",
       "        6.29068147e-01, -4.20855797e-01, -3.75286537e-01,  1.77885970e-01,\n",
       "        9.77248454e-01,  1.76781183e-02,  4.89480383e-01,  7.42718880e-01,\n",
       "       -5.76446240e-02,  3.31525399e-01, -2.88255258e-01, -2.26693455e-02,\n",
       "        5.21837659e-01, -1.96507813e-01, -5.47155233e-01,  1.25160180e-02,\n",
       "       -2.66761573e-01,  1.52969447e-01, -6.37570491e-01, -5.42342140e-02,\n",
       "        6.28757097e-01,  7.46052316e-01, -1.88470703e-01,  3.21771419e-02,\n",
       "        5.75350987e-02, -1.38833109e-01,  1.68983996e-01, -2.25347807e-01,\n",
       "       -7.10564686e-01,  3.80240281e-01, -3.97450305e-01,  3.92858050e-02,\n",
       "        1.96420556e-01, -6.69784239e-01,  3.83276805e-01,  5.06241182e-01,\n",
       "       -1.54494138e-01, -4.36577244e-01,  4.97605801e-01,  3.45863904e-01,\n",
       "       -4.64544807e-01,  1.87464831e-01,  3.18504494e-01,  1.03976310e-01,\n",
       "       -2.27747055e-02, -1.50723455e-01, -1.08790109e-01, -1.74550233e-01,\n",
       "       -4.80424308e-02, -4.84910745e-01, -3.00618561e-01, -4.15070321e-01,\n",
       "       -4.09826898e-01, -4.19749125e-02, -1.38633825e-01,  4.80106243e-01,\n",
       "       -9.04193744e-01, -4.64303173e-01, -2.84872767e-01,  5.72753504e-02,\n",
       "       -1.63881222e-01, -6.22630245e-01, -1.28263486e-01, -8.49214502e-01,\n",
       "       -1.01455746e+00, -5.53295266e-01,  6.49367780e-01,  1.17095407e+00,\n",
       "       -8.17879686e-01, -1.31948523e-01, -3.76351261e-02, -6.76255725e-01,\n",
       "        2.65037188e-02,  1.69192315e-01, -4.73584223e-01,  2.98104965e-01,\n",
       "        1.79864690e-01, -4.79872245e-01, -1.66900414e-02,  1.46814872e-01,\n",
       "        3.91611740e-01,  4.22172477e-01,  2.35958422e-01,  3.86864576e-01,\n",
       "       -3.85328954e-01,  5.44285899e-01, -3.50575005e-02, -8.43989932e-01,\n",
       "       -2.65528751e-01, -1.04851814e-01, -4.46783942e-01,  1.03210246e-01,\n",
       "       -3.74754178e-01,  9.39092965e-03,  5.82254697e-02,  3.74149566e-01,\n",
       "       -5.21959475e-01, -3.12431002e-01,  7.50553685e-01, -5.49853668e-02,\n",
       "        2.81150330e-01,  3.22514823e-01,  3.08659733e-01,  2.49565143e-01,\n",
       "        5.17470429e-02, -4.64098284e-01,  1.81411255e-01,  1.22943095e-01,\n",
       "       -7.65263492e-01, -1.06252719e-01,  1.92247490e-01,  1.46814859e-02,\n",
       "       -2.55904672e-01, -2.19450374e-01, -3.56933709e-02,  1.63672303e-01,\n",
       "       -9.54463049e-01, -5.55576504e-01, -2.43557334e-01, -6.10693177e-02,\n",
       "        3.83539185e-02, -2.54264860e-01, -8.77562863e-02, -1.80955914e-01,\n",
       "        7.49481162e-02,  1.00284093e+00, -3.08774022e-01, -1.50527065e-01,\n",
       "        3.36679027e-01,  1.47000785e+00, -2.11826702e-01,  8.59926694e-01,\n",
       "        9.39534832e-01,  2.39156405e-01, -3.25244718e-01,  4.67936936e-01,\n",
       "        4.64140443e-01,  1.72119794e-01, -1.46645872e-01, -4.24902797e-01,\n",
       "        5.99800750e-03, -7.04478196e-01, -2.51281906e-01,  8.08678948e-02,\n",
       "        6.65270634e-01,  3.64936127e-01,  3.24212440e-01, -6.65532845e-01,\n",
       "       -2.48407253e-01, -4.94364201e-01,  2.51025640e-01,  2.07188333e-02,\n",
       "       -5.09161652e-01,  1.44254299e-01, -2.69616432e-01,  7.95143017e-02,\n",
       "       -7.63937462e-01, -1.44189664e-01, -1.77943845e-02,  2.95339261e-01,\n",
       "       -2.27946288e-01,  4.21980716e-01, -1.33312800e-01, -3.06075839e-01,\n",
       "       -1.62958275e-01,  4.77318226e-02, -1.85507988e-01, -1.40510859e-01,\n",
       "       -1.48581024e-01, -7.14470067e-01,  2.93871546e-01,  5.21770946e-01,\n",
       "        2.56738408e-01,  5.91117446e-01, -2.77592342e-01,  2.82766693e-01,\n",
       "        1.87932292e-01, -5.64860023e-01, -5.31085810e-01,  4.12343556e-01,\n",
       "        3.99614660e-01,  2.15745423e-01, -3.99248038e-01,  3.18041595e-01,\n",
       "        7.42174184e-02, -5.18688440e-01,  3.52662004e-01, -2.94758838e-01,\n",
       "        3.41457651e-01,  1.77471377e-01, -1.30602669e-02,  5.78621293e-01,\n",
       "       -1.44532085e-01,  6.12199304e-01,  1.19680203e-02,  1.77523203e-01,\n",
       "        1.97781042e-01, -4.16613140e-01,  5.62356704e-02, -2.12920160e-02,\n",
       "        4.71780158e-01,  1.07286668e+00, -6.74303103e-01, -3.79993721e-01,\n",
       "       -8.82866223e-01,  2.07027333e-01,  6.15845778e-02, -1.41206628e-01,\n",
       "        4.78611162e-01, -1.06079533e+00,  4.30584440e-01,  6.28625103e-02,\n",
       "       -4.29569240e-01,  5.18436742e-01,  9.92899071e-01, -3.55723512e-01,\n",
       "        5.56915480e-01,  2.87668313e-01, -2.52721114e-01,  4.60792546e-01,\n",
       "       -2.00826544e-01, -1.78879492e-02,  3.11007497e-02, -9.49213220e+00,\n",
       "        1.81937605e-01, -4.66650423e-01,  6.61058565e-02,  5.88533298e-01,\n",
       "        6.78042038e-01, -7.80833940e-01, -2.52728459e-01,  5.64324918e-01,\n",
       "        4.83444569e-01,  1.18521858e-01, -6.12206167e-01, -1.98705282e-01,\n",
       "        4.70960395e-01,  3.04300590e-01,  7.79211917e-01, -1.02405609e-01,\n",
       "        1.04979711e+00,  1.86091831e-01,  2.24259308e-01,  4.53470774e-01,\n",
       "        4.10720747e-01,  2.44572404e-01, -5.77502211e-01,  5.16164067e-02,\n",
       "        8.10872114e-02,  3.21915442e-01,  2.89698640e-01,  1.36281026e-01,\n",
       "        4.95972725e-01,  5.45178489e-01, -8.03413221e-01, -3.70665061e-01,\n",
       "        3.21626002e-01, -1.81283787e-01, -5.53982008e-01,  3.71642663e-01,\n",
       "       -7.28270625e-02, -7.78933247e-02,  6.74969425e-02, -5.10885675e-01,\n",
       "        6.87841965e-01,  3.05913432e-01, -6.49860961e-02, -4.58524261e-01,\n",
       "       -1.31808369e-01, -2.64550397e-02,  2.86224685e-01,  1.53717954e-01,\n",
       "       -6.24102917e-01,  1.76380054e-01, -6.21923045e-01, -3.27559544e-02,\n",
       "        4.24122841e-01, -1.70396791e-01,  2.43098219e-02, -2.54182681e-01])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfIdfGloveTransformer(model).fit(documents)\n",
    "result = tfidf.transform(documents)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNeighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrapper of sklearn balltree to put in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "from sklearn.neighbors import BallTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "wrapper for sklearn BallTree that can be added to a pipeline\n",
    "'''\n",
    "\n",
    "class BallTreePredictor():\n",
    "    \n",
    "    def __init__(self,k=5):\n",
    "        self.tree = None\n",
    "        self.k=k\n",
    "        \n",
    "    def set_neighbors(self,k):\n",
    "        self.k = k\n",
    "        \n",
    "    def fit(self,X,y=None):\n",
    "        self.tree = BallTree(X)\n",
    "        return self\n",
    "        \n",
    "    def predict(self,X):\n",
    "        return self.tree.query(X,self.k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 7.66705467],\n",
       "        [0.        , 8.68959395],\n",
       "        [0.        , 7.78825885],\n",
       "        [0.        , 7.66705467],\n",
       "        [0.        , 7.78825885]]), array([[0, 3],\n",
       "        [1, 3],\n",
       "        [2, 4],\n",
       "        [3, 0],\n",
       "        [4, 2]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "\n",
    "tree = BallTreePredictor(k=2).fit(result)\n",
    "tree.predict(result[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([(\"json\",JsonTransform()),(\"embedder\",TfIdfGloveTransformer(model)),(\"tree\",BallTreePredictor())])\n",
    "pipe.fit(data) # fit and predict directly on json files\n",
    "pipe.predict(data[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
