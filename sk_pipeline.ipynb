{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sk learn classes\n",
    "\n",
    "Clases para generar un pipeline de sk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import json\n",
    "from functools import reduce\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "transformer object that turns the data json into arrays of tokenized words.\n",
    "'''\n",
    "\n",
    "class JsonTransform():\n",
    "    \n",
    "    '''\n",
    "    add category determines if tag category is added to the final arrays.\n",
    "    '''\n",
    "    def __init__(self,add_category=False):\n",
    "        self.add_category = add_category\n",
    "        \n",
    "    '''\n",
    "    returns arrays of word arrays from tags\n",
    "    '''    \n",
    "\n",
    "    def transform(self,X):\n",
    "        return [ self.tag_array_to_word_array(instance) for instance in self.data_to_tags(data)]\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    returns tag as array of words (no ':').\n",
    "    add_category determines if the tag category is added to the array.\n",
    "    '''\n",
    "    def tag_to_words(self,tag):\n",
    "        category, text = tag.split(\":\")\n",
    "        if self.add_category:\n",
    "            return word_tokenize(\"{} {}\".format(category,text).lower())\n",
    "        return word_tokenize(text.lower())\n",
    "\n",
    "    '''\n",
    "    transforms array of tags into array of words.\n",
    "    add_category determines if the tag categories are added to the text.\n",
    "    '''\n",
    "    def tag_array_to_word_array(self,tags):\n",
    "        aux_tags = list(tags)\n",
    "        aux_tags[0] = self.tag_to_words(tags[0])\n",
    "        return reduce(lambda x,y : x + self.tag_to_words(y),aux_tags)\n",
    "\n",
    "    '''\n",
    "    returns array of tag arrays from original json.\n",
    "    '''\n",
    "    def data_to_tags(self,data):\n",
    "        return [instance[\"tags\"] for instance in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "#constants\n",
    "DATA_PATH=\"data.json\"\n",
    "data = json.load(open(DATA_PATH))\n",
    "json_transformer = JsonTransform(False)\n",
    "documents = json_transformer.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "\n",
    "import numpy as np\n",
    "from gensim import corpora\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculates embedding, mapping a tokenized document to a vector.\n",
    "To calculate the vector we use a weighted average of precomputed Glove Vectors. \n",
    "Weights of the average are given by TFIDF scores.\n",
    "'''\n",
    "\n",
    "class TfIdfGloveTransformer():\n",
    "    \n",
    "    def __init__(self,word_embedder,):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self,X):\n",
    "        pass\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
